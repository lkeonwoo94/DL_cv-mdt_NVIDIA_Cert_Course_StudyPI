{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpjKNOI144hi"
   },
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6d0ifyP44hk"
   },
   "source": [
    "# TensorFlow로 단어 생성하기\n",
    "\n",
    "## 순환 신경망 (Recurrent Neural Networks) 소개\n",
    "\n",
    "### 데이터 준비 (Data Preparation)\n",
    "\n",
    "이 섹션에서는 이전 단어로부터 문장의 다음 단어를 예측하여 언어에 대한 이해를 생성하는 모델을 만들 것입니다. \n",
    "\n",
    "이전 실습에서는 레이블 된 이미지들로 구성된 데이터셋을 네트워크에 노출시켰습니다. 이번에는 **말뭉치(corpus)**를 학습하도록 설계된 네트워크에 많은 양의 텍스트들을 노출시킬 예정입니다.\n",
    "\n",
    "우선 여러분은 영어라는 언어의 아주 조금의 부분이 되는 부분집합과 네트워크가 언어에 대해 알게 될 모든 것을 두 문장으로 표현한 작은 말뭉치를 사용하는 쉬운 예로부터 시작해보겠습니다. 여기서부터, 우리는 실제 세계를 더 잘 대표하기 위한 네트워크를 만들어낼 수 있게 될 것입니다.\n",
    "\n",
    "첫째로 우리의 사전(아래의 셀을 클릭하고 Shift와 Enter 키를 눌러 코드를 실행합니다.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTFK340544hl"
   },
   "outputs": [],
   "source": [
    "small_dict=['EOS','a','my','sleeps','on','dog','cat','the','bed','floor'] #'EOS' means end of sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjEAwsLA44hr"
   },
   "source": [
    "다음으로, 우리는 네트워크에 언어를 학습시키기 위해 사용할 작은 말뭉치를 만들 수 있습니다. 우리 사전에 있는 단어들로 몇 개의 문장을 만들어 봅시다. numpy 배열 'X'의 첫 번째 벡터는 ['my','cat','sleeps','on','my','bed', 'EOS']를 나타냅니다. \n",
    "\n",
    "이 모델을 모델로 사용하여 **##FIXME##** vector를 ['a', 'dog', 'sleeps', 'on', 'the', 'floor', 'EOS'] 문장으로 대체하십시오.\n",
    "이 시점에서, 우리는 힌트와 정의를 주는 새로운 방법을 소개하겠습니다. 힌트를 원한다면 [여기](#hint \"The second line should be X=np.array([[2,6,3,4,2,8,0],[1,5,3,4,7,9,0]]),dtype=np.int32)\")에 마우스를 올리세요. 앞으로 이 실습의 나머지 부분에서도 계속 확인 할 수 있게 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqXfHWLt44hs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'dog', 'sleeps', 'on', 'the', 'floor', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #numpy is \"numerical python\" and is used in deep learning mostly for its n-dimensional array\n",
    "# X=np.array([[2,6,3,4,2,8,0],[##FIXME##]],dtype=np.int32) \n",
    "X=np.array([[2,6,3,4,2,8,0],[1,5,3,4,7,9,0]],dtype=np.int32) \n",
    "    \n",
    "# (#hint \"The second line should be X=np.array([[2,6,3,4,2,8,0],[1,5,3,4,7,9,0]]),dtype=np.int32)\")\n",
    "print([small_dict[ind] for ind in X[1,:]]) #Feel free to change 1 to 0 to see the other sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Myxoul-644hy"
   },
   "source": [
    "이제 데이터를 확보했으므로 네트워크를 위해 데이터를 재구성해야 합니다. 단어는 기본적으로 이미지와 다른 유형의 데이터입니다. 28X28 그레이스케일 이미지는 각 셀이 해당 픽셀의 \"그레이 정도(greyness)\"를 나타내는 28X28 매트릭스로 표시됩니다. 256X256 컬러 이미지는 각 셀에 각 픽셀의 \"적색\", \"녹색\", \"청색\"이 포함된 `256X256X3` [tensor](#tensor \"a vector, matrix, or any other *block* of n-dimensional data\")\"로 표시됩니다.\n",
    "\n",
    "우리는 이미지를 분류할 때 입력 tensor가 확률 벡터(vector of probabilities)로 어떻게 바뀌는 지를 설명하기 위해 TensorFlow(또는 다른 프레임워크)를 사용하였습니다.\n",
    "단어를 입력으로 사용하려면 먼저 단어를 tensor로 변환해야 합니다. 이 예에서는 각 단어가 하나의 '1'과 그 외는 '0'인 벡터로 표시되는 \"one-hot encoding\"을 사용합니다. 이 vector 값들은 단어에 따라 특정 위치에 하나의 '1'을 갖는 사전의 길이(length of the dictionary)가 됩니다.\n",
    "\n",
    "이제 TensorFlow [세션](#sess \"where computational graphs described in TensorFlow are run\")을 실행하여 입력 데이터를 one-hot encoding으로 변환하고, 어떻게 보이는지 시각화 해보겠습니다. TensorFlow의 embedding_lookup 및 unstack 함수를 사용하면 쉽게 작업을 수행할 수 있습니다. One-hot encoding의 경우, 사전과 입력 데이터셋의 길이로 구성된 [identity matrix](#idmat \"A matrix with ones in the diagonal and zeros everywhere else\")인 embedding_lookup을 전달합니다. 이 작업은 실습의 일부로 수행될 수도 있지만, 입력을 더 잘 시각화하기 위해 따로 진행하도록 하겠습니다.\n",
    "\n",
    "우리가 사용하고 있는 영어의 하위 집합(subset)이 얼마나 작은지를 상기하기 위해, **##FIXME##**을 사전의 길이로 대체합니다. 힌트를 얻기 원한다면, [여기](#dict_length \"np.identity function내의 ##FIXME##를 len(small_dict)으로 고치세요.\")에 마우스를 올리세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLpen-dZ44hy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoded inputs\n",
      "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "shape of the input\n",
      "(2, 7, 10)\n",
      "reshaped input for training\n",
      "[[array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]), array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]), array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "tf.reset_default_graph()\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        \n",
    "#         result=tf.nn.embedding_lookup(np.identity(##FIXME##), X).eval()\n",
    "        result=tf.nn.embedding_lookup(np.identity(len(small_dict)), X).eval()\n",
    "        #dict_length \"np.identity function내의 ##FIXME##를 len(small_dict)으로 고치세요.\n",
    "        \n",
    "        # embedding_lookup이 알아서 one-hot encoding으로 바꿔줍니다.\n",
    "        \n",
    "        \n",
    "        example_input=sess.run([tf.unstack(result,X.shape[1],1)])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "print('one-hot encoded inputs')\n",
    "print(result)\n",
    "print('shape of the input')\n",
    "print(result.shape)\n",
    "print('reshaped input for training')\n",
    "print(example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXx--qOu44h2"
   },
   "source": [
    "이제 우리 데이터가 생겼습니다!\n",
    "\n",
    "신경망이 랜덤화 된 값으로 채워지기 시작했음을 기억하십시오. 데이터 노출을 통해 네트워크는 입력에서 출력까지의 정확한 매핑을 만들기 위해 \"학습\" 합니다.\n",
    "\n",
    "### 단어 생성 워크플로우 (Word Generation)\n",
    "\n",
    "여러분의 이미지 분류 네트워크의 출력 레이블은 이미지 입력으로부터 예측됩니다. 우리의 언어 처리 네트워크는 이전 단어의 입력으로부터 다음 단어 예측을 출력해낼 것입니다.\n",
    "\n",
    "예를 들어, 문장을 가지고 직접 해보겠습니다.\n",
    "\n",
    "우리의 문장은 \"나의(My)\"로 시작합니다.\n",
    "\n",
    "여러분이 알고 있는 모든 단어들과 일생 동안 관찰해 온 패턴을 생각해 봤을 때, \"My\"라는 단어 뒤에는 어떤 단어가 나올 수 있을까요?\n",
    "\n",
    "좋습니다. 이제 여러분이 추측했으니, 두 번째 단어가 \"친구(friend)\"라는 것을 알게 됩니다.\n",
    "\n",
    "이 문장에 대해 조금 더 배우고, 첫 두 단어를 사용하여 문장의 세 번째 단어를 추측할 수 있습니다.\n",
    "\n",
    "그 다음 여러분은 세 번째 단어가 \"went\"라는 것을 예측하고, 오류를 범했다면, 다시 추측하게 됩니다. 여러분은 이 문장 구조에 대해 처음 생각했던 것보다 더 많이 알고 있습니까? 만약 여러분이 이 문장을 처음 보았거나, 또는 몇 천번 쯤 본 문장이건 간에, 여러분은 아마도 모든 문장 구조에 대해서도 더 많이 알고 있을 것입니다.\n",
    "\n",
    "이것은 네트워크가 언어에 대해 배우는 방식과 유사합니다. 이러한 유형의 네트워크를 **순환 신경망(RNN)**이라고 합니다. RNN은 충분한 시간과 데이터셋이 있다면, 어떻게 \"주어\"가 \"동사\"와 관련 있는지, 언제 구두점들이 보통 필요한지 등 모든 경우의 수를 학습할 수 있습니다. RNN은 예측한 다음 단어와 실제 다음 단어 사이의 오류를 줄여가면서 학습합니다. RNN들은 예측을 가능하게 한 단어들을 \"기억\"하여 문장의 구조를 형성합니다.\n",
    "\n",
    "여러분이 사용할 수 있는 가장 간단한 RNN에서 단 하나의 레이어만 가지고, 약 8개의 단어로 이루어진 두 문장에서 각 단어 사이의 관계가 무엇인지를 배울 수 있는지를 봅시다.\n",
    "아래의 **##FIXME##**을 숫자 10으로 바꾸어 10개의 epoch로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksyjfqlN44h5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iteration: ', 0, ' loss: ', 2.7247705)\n",
      "('iteration: ', 5, ' loss: ', 1.9134545)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[5 5 2 5 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 여기가 실제로 학습시키는 코드\n",
    "\n",
    "\n",
    "# epochs=##FIXME##\n",
    "epochs=10\n",
    "plot_loss=[]\n",
    "num_hidden=24\n",
    "num_steps=X.shape[1]\n",
    "dict_length=len(small_dict)\n",
    "batch_size=2\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## Make Variables\n",
    "variables_dict = {\n",
    "    \"weights1\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],stddev=1.0,dtype=tf.float32),name=\"weights1\"),\n",
    "    \"biases1\": tf.Variable(tf.truncated_normal([dict_length],stddev=1.0,dtype=tf.float32), name=\"biases1\")}\n",
    "# w와 b가 어떤식으로 define 되어있는지\n",
    "\n",
    "\n",
    "# Create input data\n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), X) #[batch,num_steps,dictionary_length][2,6,7]\n",
    "y=np.zeros((batch_size,num_steps),dtype=np.int32)\n",
    "y[:,:-1]=X[:,1:]\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), y),num_steps,1) #[batch,num_steps,dictionary_length][2,6,7]\n",
    "\n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "\n",
    "#Create our LSTM\n",
    "# 여기가 architecture를 선언하는 부분. LSTM을 선언하고 한 층을 쌓고, 쌓은 것으로 RNN을 만들고\n",
    "\n",
    "cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "# 셀 선언. \n",
    "\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden]) #[12==batch_size*num_steps,num_hidden==12]\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights1\"]) +variables_dict[\"biases1\"]\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "plot_loss=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        # 실제로 학습이 되는 부분\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)        \n",
    "        for i in range(epochs):\n",
    "            loss,_,y_target,y_pred,output=sess.run([cost,optimizer,y_target_reshape,pred,outputs])\n",
    "            plot_loss.append([loss])\n",
    "\n",
    "            if i% 5 ==0:\n",
    "                print(\"iteration: \",i,\" loss: \",loss)\n",
    "                \n",
    "        print(y_target)\n",
    "        print(np.argmax(y_pred,1))          \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foS6EzDq44h8"
   },
   "source": [
    "여러분의 RNN은 두 문장을 10번 보았습니다. RNN은 새로운 단어를 볼 때마다 다음 단어를 예측하려고 시도합니다. TensorFlow가 ~ 2.15의 예측에 \"손실(loss)\" 또는 오류(error)를 보여주고 있습니다. 샘플 문장을 통해 이것이 무엇인지 한 번 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hPs6vpT44h-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence\n",
      "['my', 'cat', 'sleeps', 'on', 'my', 'bed', 'EOS']\n",
      "Predicted Words\n",
      "['cat', 'sleeps', 'on', 'my', 'bed', 'EOS', 'EOS']\n",
      "정답 : cat, sleeps, on, my, bed, EOS, EOS\n"
     ]
    }
   ],
   "source": [
    "#Lets look at one input data point at each step and its prediction\n",
    "print(\"Input Sentence\")\n",
    "sn=0 #The sentence number\n",
    "print([small_dict[ind] for ind in X[sn,:]])\n",
    "print(\"Predicted Words\")\n",
    "print([small_dict[ind] for ind in np.argmax(y_pred[sn::2],1)])\n",
    "\n",
    "\n",
    "print('정답 : cat, sleeps, on, my, bed, EOS, EOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdFQDkfe44iC"
   },
   "source": [
    "위 출력은 각 \"예측 단어(Predicted Word)\"가 \"입력 문장(Input Sentence)\"에서 적합한 단어로 예측되었음을 알 수 있습니다. 예를 들어, 첫 번째 \"예측 단어(Predicted Word)\"는 \"나의(My)\"라는 입력 단어를 따라 예측되었고, 두 번째 예측 단어는 \"나의 고양이(My cat)\"라는 두 단어를 따라 예측되었다.\n",
    "우리는 적어도 학습에 사용되는 문장들을 예측할 수 있을까요? 문장의 첫 단어를 전달하여 얻은 결과값은 여러분의 원래 문장이 되어야 합니다. 무슨 일이 생겼습니까?\n",
    "\n",
    "### 성능 향상\n",
    "\n",
    "#### 추가 실습\n",
    "\n",
    "코드 블록의 반복 횟수를 300개로 증가해 보십시오. 이것이 원래 문장을 예측하는 네트워크의 능력에 어떻게 영향을 미치는가요?\n",
    "학습 시간이 늘어나면 물론 성능을 향상시킬 수 있습니다. 하지만, 우리가 여전히 너무 작은 크기의 (장난감 수준의) 데이터셋을 사용하고 있다는 것을 기억하세요.\n",
    "\n",
    "#### 심층 네트워크 \n",
    "\n",
    "여러분의 작은 샘플에서 문장을 완벽하게 예측할 수 있었겠지만, 다음에는 좀 더 복잡한 예를 들어 보겠습니다. 이제 성능에 영향을 미칠 수 있는 몇 가지 레버(lever), 즉 네트워크의 깊이와 \"드롭아웃(dropout)\"이라는 작업을 살펴보겠습니다.\n",
    "심층 모델은 더 복잡한 기능을 의미합니다. TensorFlow에서 심층 모델을 구축하기 원한다면, 여러분은 레이어를 여러 겹으로 만들면 됩니다.\n",
    "\n",
    "RNN을 2개, 4개 레이어로 학습시켜봅시다. RNN의 레이어 수를 변경하려면 어떤 매개변수를 설정해야 합니까? 힌트를 보려면 [여기](#정답1 \"num_layers=2 or 4. 이는 lstm_cell들이 생성되는 'for' loop에서 사용됩니다.\")에 마우스를 올리세요.\n",
    "\n",
    "드롭아웃은 실제로 모델이 학습 중에도 일부 매개 변수를 \"잊어버려(forget)\"라고 요청하여 모델의 일반화 능력을 향상시킵니다. 드롭아웃 값을 조정할 수 있는 위치를 보려면, [여기](#정답2 \"dropout = ___, 1.0이면 = none -remember everything 그리고 0.0이면 all -remember nothing의 의미를 갖습니다. dropout은 다음의 줄의 code에서 사용됩니다. lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,input_keep_prob=dropout,output_keep_prob=dropout)\")에 마우스를 올리세요.\n",
    "이 둘을 실험해서 성능 향상이 가능한지 알아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fi-Cf2RY44iD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iteration: ', 0, ' loss: ', 2.6045303)\n",
      "('iteration: ', 25, ' loss: ', 1.0563842)\n",
      "('iteration: ', 50, ' loss: ', 0.4670295)\n",
      "('iteration: ', 75, ' loss: ', 0.22977774)\n",
      "('iteration: ', 100, ' loss: ', 0.10870053)\n",
      "('iteration: ', 125, ' loss: ', 0.010678169)\n",
      "('iteration: ', 150, ' loss: ', 0.002501288)\n",
      "('iteration: ', 175, ' loss: ', 0.001614981)\n",
      "('iteration: ', 200, ' loss: ', 0.001240606)\n",
      "('iteration: ', 225, ' loss: ', 0.0010056081)\n",
      "('iteration: ', 250, ' loss: ', 0.00083935895)\n",
      "('iteration: ', 275, ' loss: ', 0.00071514456)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[6 5 3 3 4 4 2 7 8 9 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Now let's try multiple layers \n",
    "plot_loss2=[]\n",
    "num_hidden=24\n",
    "num_steps=X.shape[1]\n",
    "dict_length=len(small_dict)\n",
    "batch_size=2\n",
    "# num_layers=##FIXME##\n",
    "num_layers=4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## Make Variables\n",
    "variables_dict = {\n",
    "    \"weights1\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],stddev=1.0,dtype=tf.float32),name=\"weights1\"),\n",
    "    \"biases1\": tf.Variable(tf.truncated_normal([dict_length],stddev=1.0,dtype=tf.float32), name=\"biases1\")}\n",
    "\n",
    "\n",
    "# Create input data\n",
    "#small_dict=['EOS','i','will','walk','the','dog','cat','run']\n",
    "#X=np.array([[1,2,7,4,5,0],[1,2,3,4,6,0]],dtype=np.int32)  \n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), X) \n",
    "y=np.zeros((batch_size,num_steps),dtype=np.int32)\n",
    "y[:,:-1]=X[:,1:]\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), y),num_steps,1) \n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "# dropout = ##FIXME##\n",
    "dropout = 1\n",
    "# dropout = 0.5\n",
    "\n",
    "\n",
    "##################### Create a multilayer RNN ####################\n",
    "layer_cell=[]\n",
    "for _ in range(num_layers):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,\n",
    "                                          input_keep_prob=dropout,\n",
    "                                          output_keep_prob=dropout)\n",
    "    layer_cell.append(lstm_cell)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell(layer_cell, state_is_tuple=True)\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden])\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights1\"]) +variables_dict[\"biases1\"]\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        for i in range(300):\n",
    "            loss,_,y_target,y_pred,output=sess.run([cost,optimizer,y_target_reshape,pred,outputs])\n",
    "            plot_loss2.append([loss])\n",
    "            \n",
    "            if i% 25 ==0:\n",
    "                print(\"iteration: \",i,\" loss: \",loss)\n",
    "                \n",
    "        print(y_target)\n",
    "        print(np.argmax(y_pred,1))         \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qwsD2-x44iM"
   },
   "source": [
    "#### 단일/다계층 RNN의 loss를 비교하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LwqaB1844iN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FdX9//HXhxA2CSAYEAkICijIEjCAVFRUBEQEW+oui6K2tmil2n5prf5Qv622Vq1b3VARRXAt0mpdMV83FCINuwoq1CDKorKIKJDP74+ZhAsmZL2Ze3Pfz8fjPu69c87MfCYD+eScM3PG3B0RERGAOlEHICIiiUNJQUREiikpiIhIMSUFEREppqQgIiLFlBRERKSYkoJIOZjZ781sStRxlMXMDjGzrdVdV1KH6T4FiQczWwVc6O6v1PB+xwEPAN+Gi9YDucAN7v5hTcZSFjNrByyLWbQfsA0o+k95sru/UeOBSUpTS0Fqo7nu3hhoCgwiSBDvmVm3ymzMzOpWZ3BF3P2/7t646BUu7hmz7AcJwczS4hGLSBElBalxZnaRma00sy/NbLaZHRQuNzO71czWmdlmM1tc9IvczIaZ2TIz22Jma8zsyrL24+673P0jd/8F8H/A5HBbA82sYK+YVpnZoPDzZDN7ysweNbPNwLhw2aNheXszczMba2b/NbMNZnZVzLYamtnDZvaVmS03s9/uvb8K/KweNbO7zOwFM/sGOMbMRphZfvgz+q+ZXR1Tv6OZecz3N83sWjN7O/zZvWBmzStaNyw/P+Z4f29mBWY2sDLHJYlLSUFqlJmdANwAnAG0BlYDM8PiwcCxQGeCv/LPADaGZQ8AP3P3DKAbMKeCu34GOKYC9UcCTwHNgOml1BkAHAacCFxjZl3C5f8PaA8cApwEnFfBWPd2DnAtkAHMBbYC54axnQr8ysyGl7H+WKAVQRfVryta18y6A7cDZwFtgEzgwEofkSQsJQWpaecCD7r7Anf/Dvgd0N/M2gM7CH7xHU4w3rXc3deG6+0AuppZE3f/yt0XVHC/nwHNy6y121x3n+Xuhe7+bSl1rnX3b919IbAQ6BkuPwP4UxhnAcEv06r4h7vPDWP5zt3nuPvS8PtCgqR63D7Wf8DdV7j7NuBJILsSdU8HZrn72+F5+0MVj0kSlJKC1LSDCFoHALj7VoLWQBt3nwPcCdwFrDOz+8ysSVh1FDAMWG1m/2dm/Su43zbAlxWo/2k56nwe83kbUDQucNBe65dnW+WOxcz6m1muma03s03AhcABlYizInX3OCZ3/wb4qhyxS5JRUpCa9hlwcNEXM9sPaAGsAXD32939SKArQTfSb8Ll8919JNASmAU8UcH9/hgoGrj9BmgUE0MaQXdIrKpclrcWyIr53rYK2yoplpnA00Bbd28KTAGsivsoyx7HFJ63/eO8T4mAkoLEU7qZNYh51QVmAOebWbaZ1Qf+BLzr7qvMrI+Z9TOzdIJf3NuBQjOrZ2bnmllTd98BbAYKy9q5maWZWQczuwMYSNAvD/Ah0MDMTgn39QegfjUe9xPA78xsfzNrA0yoxm1D0MX2pbtvN7OjCPr54+1J4DQzO8rM6gHX1cA+JQJKChJPzxNcDlr0mhzet3A1wV+6a4FD2f1LrQlwP0G3xGqCbqWbwrLRwKrwaqCfE4xNlKZ/eFPWZoJ7FJoAfdx9MYC7bwJ+QfAX9hqCBFSpq4NKcV24vU+AVwgGrL+rxu1fAtxgZluA31PxVlOFufsiYCJBcviM4NxspHqPSxKAbl4TiTMzuwQ4y933NRicVMKxnq+Bg929qmMmkkDUUhCpZmbW2syONrM6ZnYYcAXwj6jjqqrw/ohGZtYYuBlYoIRQ+ygpiFS/esC9wBaC+ymeBf4eaUTV48cEXUcFBPdhnB1pNBIX6j4SEZFiaimIiEixuEz0FU8HHHCAt2/fPuowRESSynvvvbfB3fe+H+cHki4ptG/fnry8vKjDEBFJKma2uuxa6j4SEZEYSgoiIlJMSUFERIol3ZiCiFTNjh07KCgoYPv27VGHInHQoEEDsrKySE9Pr9T6SgoiKaagoICMjAzat2+PWbwnV5Wa5O5s3LiRgoICOnToUKltqPtIJMVs376dFi1aKCHUQmZGixYtqtQKTJ2kMHcu3HBD8C6S4pQQaq+qntvU6D6aOxdOPBG+/x7q1YNXX4X+FX1wl4hI7ZcaLYXc3CAh7NoVvOfmRh2RSMq64IILaNmyJd26ddtnvcaN9/XU0PhZtWpVibG988479OvXj+zsbLp06cLkyZN56KGHyM7OJjs7m3r16tG9e3eys7OZNGkSU6dOxcx45ZVXircxa9YszIynnnqqJg+pQlKjpTBwYNBCKGopDBwYdUQiKWvcuHFMmDCBMWPGRB0KADt37qRu3bJ/FY4dO5YnnniCnj17smvXLj744AO6du3K+eefDwSzLbz22msccEDwuOypU6fSvXt3Zs6cyaBBgwCYMWMGPXv2jN/BVIPUaCn07x90GV1/vbqORCqjGsfkjj32WJo3b16pdf/5z3/Sr18/evXqxaBBg/jiiy8oLCykU6dOrF+/HoDCwkI6duzI+vXrWb9+PaNGjaJPnz706dOHt956C4DJkyczevRojj76aEaPHl2ufa9bt47WrVsDkJaWRteuXctc55hjjmHevHns2LGDrVu3snLlSrKzsyt17DUlNVoKECQCJQORikugMbkBAwbwzjvvYGZMmTKFv/zlL9x8882cd955TJ8+ncsvv5xXXnmFnj17kpmZyTnnnMPEiRMZMGAA//3vfxkyZAjLly8HYNmyZbz55ps0bNiwXPueOHEihx12GAMHDmTo0KGMHTuWBg0a7HMdM2PQoEG8+OKLbNq0iREjRvDJJ59U+ecQT6nRUhCRykugMbmCggKGDBlC9+7duemmm1i6dCkQjFNMmzYNgAcffLC4S+eVV15hwoQJZGdnM2LECDZv3szWrVsBGDFiRLkTAsA111xDXl4egwcP5rHHHmPo0KHlWu+ss85i5syZzJw5k7PPTvznEikpiMi+FY3JpaXFbUzu008/LR6wveeee0qtd+mllzJhwgQWL17MvffeW3w9ftu2bWnVqhVz5sxh3rx5nHzyyUDQlfTOO++Qn59Pfn4+a9asKR7A3m+//Soc56GHHsoll1zCq6++ysKFC9m4cWOZ6/Tt25fFixezYcMGOnfuXOF91rTU6T4SkcopGpPLzQ0SQhy6jtq2bUt+fn6Z9TZt2kSbNm0AePjhh/cou/DCCznvvPMYPXo0aWlpAAwePJg77riD3/zmNwDk5+dXuk//ueeeY9iwYZgZK1asIC0tjWbNmpVr3RtvvLHMrqZEoZaCiJStf3/43e+qJSGcffbZ9O/fnw8++ICsrCweeOCBEutt27aNrKys4tctt9zC5MmTOf300znyyCOLr/IpMmLECLZu3VrcdQRw++23k5eXR48ePejates+WyGximIrej355JM88sgjHHbYYWRnZzN69GimT59enHzKcvLJJ3P88ceXq27Uku4ZzTk5OV7Zh+xs2gT160OSJGyRuFi+fDldunSJOoxql5eXx8SJE3njjTeiDiVyJZ1jM3vP3XPKWjdlWgrz5kGzZkErWERqlxtvvJFRo0Zxww03RB1K0kuZpNC1K9Sp48y75U3NfyRSy0yaNInVq1czYMCAqENJeimTFBovnktXX8r8OVuCa66VGEREfiBlkgK5ufRlHvPog3+n+Y9EREoSt6RgZm3N7DUzW2ZmS83sVyXUGWhmm8wsP3xdE694GDiQPnXz2cgBrErvpPmPRERKEM/7FHYCV7j7AjPLAN4zs5fdfdle9d5w9+FxjCPQvz8nPNKAP0+dQ8NfPgL9yxyEFxFJOXFrKbj7WndfEH7eAiwH2sRrf+XR+cxe/PbfJ3DgcCUEkaiYGeedd17x9507d5KZmcnw4WX/bVh0N/KqVat47LHHipfn5eVx2WWXlbjOwIEDqexl7FXVvn17NmzYsMeyL774guHDh9OzZ0+6du3KsGHDWLx4cfEd3c2bN6dDhw5kZ2czaNAgVq1ahZnxhz/8oXgbGzZsID09nQkTJlR7zDUypmBm7YFewLslFPc3s4Vm9m8zOyLesXz6KaxYEe+9iEhp9ttvP5YsWcK3334LwMsvv1x8l3J57Z0UcnJyuP3226s1zorauXNnuepdc801nHTSSSxcuJBly5Zx44030r179+KpOEaMGMFNN91Efn5+8bMYOnTowHPPPVe8jSeffJIjjojPr8u4JwUzaww8DVzu7pv3Kl4AHOzuPYE7gFmlbONiM8szs7yi6XEr69RTYeLEKm1CRKpo2LBhxb/kZsyYscdEcZMnT+avf/1r8fdu3bqxatWqPdafNGkSb7zxBtnZ2dx6663k5uaWq6VRZNWqVRxzzDH07t2b3r178/bbbwMwZswYZs3a/Wvo3HPP5dlnn2XXrl385je/oU+fPvTo0YN7770XgNzcXI455hhGjBhRrqm0AdauXUtWVlbx9x49epS5TqNGjejSpUtxi+fxxx/njDPOKPfxVkRck4KZpRMkhOnu/sze5e6+2d23hp+fB9LN7IAS6t3n7jnunpOZmVmlmDp2hJUrq7QJkVpl4MAfvmJ+J1e4vDyKZg7dvn07ixYtol+/fhWK+cYbb+SYY44hPz+fiZX4K69ly5a8/PLLLFiwgMcff7y462n8+PFMnToVCOZZevvttznllFN44IEHaNq0KfPnz2f+/Pncf//9xVNgL1iwgNtuu40PP/ywXPv+5S9/yfjx4zn++OP54x//yGeffVau9Yp+Zp9++ilpaWkcdNBBFT7u8ojn1UcGPAAsd/dbSqlzYFgPM+sbxlP2tINV0LEjfPxxMAuwiESjR48erFq1ihkzZjBs2LAa3/+OHTu46KKL6N69O6effjrLlgXXvxx33HGsWLGC9evXM2PGDEaNGkXdunV56aWXmDZtGtnZ2fTr14+NGzeyIuyH7tu3Lx06dCj3vocMGcLHH3/MRRddxPvvv0+vXr0oTw/I0KFDefnll5k5cyZnnnlm5Q68HOJ59dHRwGhgsZkVTX/4e6AdgLvfA/wUuMTMdgLfAmd5nCdjOvRQ2LEDCgrg4IPjuSeR5FDWLTtVLS/NiBEjuPLKK8nNzd1jCuq6detSWFhY/L1oeuzyGjJkCF988QU5OTlMmTKlxDq33norrVq1YuHChRQWFu4xg+mYMWN49NFHmTlzJg899BAA7s4dd9zBkCFD9thObm5upabgbt68Oeeccw7nnHMOw4cP5/XXX2fUqFH7XKdevXoceeSR3HzzzSxbtozZs2dXeL/lEbek4O5vAlZGnTuBO+MVQ0kO/mYZ0JXVzy3h4F/s+8HhIhI/F1xwAc2aNaN79+7kxmSW9u3b869//QsIumZKelJZRkYGW7ZsKXG7L774Ypn73rRpE1lZWdSpU4eHH36YXTFdB+PGjaNv374ceOCBxeMEQ4YM4e677+aEE04gPT2dDz/8sMKD40XmzJnDUUcdRaNGjdiyZQsfffQR7dq1K9e6V1xxBccdd1ylH2daHqn1PIW5c+nxu3O4306i4xWvQq9H9YhOkYhkZWWVeBnpqFGjmDZtGkcccQT9+vUr8cE0PXr0IC0tjZ49ezJu3Dh69eq1z32dcsoppKenA9C/f3/+9Kc/Fe9n6NChe/y136pVK7p06cJpp51WvOzCCy9k1apV9O7dG3cnMzNzjwHpfenRowd16gQ99WeccQatW7dmwoQJxS2iCy+8kD59+pRrW0cccUTcrjoqklJTZ3PDDXD11cGAQloaXH99MEe8SAqprVNnV5dt27bRvXt3FixYQNOmTaMOp1I0dXZ5hY8VXFAnh5V1D9dUFyKyh1deeYUuXbpw6aWXJm1CqKrU6j4KHys4eFBPzhiymb/3PzDqiEQkgQwaNIjVq1dHHUakUispAPTvT8uDYV2dRlFHIhIZdye8GlxqmaoOCaRW91GoVSv44ouooxCJRoMGDdi4cWOVf3lI4nF3Nm7cuMclthWVei0FoGVLyM8vu55IbZSVlUVBQUG5bpiS5NOgQYM9ptGoqJRMCq1awbp1UUchEo309PQK3YErqSUlk8Lo0TBgALiDulVFRHZLyaTQp0/wEhGRPaXkQPOmTTBnDnz5ZdSRiIgklpRMCvnTl3LiicG7iIjslnpJYe5cmvz6QgA2X3kdzJ0bcUAiIokj9ZJCbi5NdgTT9G7e0bDy8/6KiNRCqZcUBg6kSb1gfvYtdffX/EciIjFSLyn070+TF54AYPP4yzV1tohIjJS8JLX+cUfx6KPQq5cevSYiEislkwLAuedGHYGISOJJve6j0Lx58J//RB2FiEhiSdmWws9+Bm3bQpyefS0ikpRStqWQkQGlPPdbRCRlpWxSaNIENm+OOgoRkcSipCAiIsVSNyl8+zmb136jaS5ERGKkZlKYO5eL/j2KKd+eCyeeqMQgIhJKzaSQm8uRO9/l1MJn4fvvNf+RiEgoNZPCwIF8ln4w/65zCtvTMzT/kYhIKDWTQv/+vHTFiwwr/BdrH31V8x+JiITilhTMrK2ZvWZmy8xsqZn9qoQ6Zma3m9lKM1tkZr3jFc/emvTuCMDmjjW2SxGRhBfPO5p3Ale4+wIzywDeM7OX3X1ZTJ2TgU7hqx9wd/ged02aBO+6LFVEZLe4tRTcfa27Lwg/bwGWA232qjYSmOaBd4BmZtY6XjHFysgI3rdurYm9iYgkhxoZUzCz9kAv4N29itoAn8Z8L+CHiQMzu9jM8swsb/369dUSU+PGwbuSgojIbnFPCmbWGHgauNzdK9VZ4+73uXuOu+dkZmZWS1zt2sFTT8GPflQtmxMRqRXiOkuqmaUTJITp7v5MCVXWAG1jvmeFy+IuIwNGjaqJPYmIJI94Xn1kwAPAcne/pZRqs4Ex4VVIRwGb3H1tvGKK5Q4vvgjvv18TexMRSQ7xbCkcDYwGFptZfrjs90A7AHe/B3geGAasBLYB58cxnj2YwYgR8Osz13BDl2nBDWy6X0FEUlzckoK7vwlYGXUc+GW8YihL4wY72PLYP4GroV49eFU3solIakvNO5pDjetsY2thQ9i1S3MgiYiQ4kkhY/90tlhTSEsLWgqaA0lEUlzKPqMZoHHLRmzNHAinXa8xBRERUjwp/PnPUK9eM77r/TseeQTOzYaGDaOOSkQkOimdFI47Lng//3yYOjW4d+HMMyMNSUQkUimdFJYsgTVroFu34PvGjdHGIyIStZQeaP7732H0aLj8cqhTB9bWyG1zIiKJK6WTQuPGsH49rF4NmZnw+edRRyQiEq2U7j4qmim1V4+dPPqTf5B1dGegZ6QxiYhEKaWTQtEzFTK3rebUx86Gp+rBYbqrWURSV8p3HwG09HWs2NWB574bpLuaRSSlpXRSGDQoeM9J+w8P2XhOK3yawmMHRhqTiEiUUjop1A07z7pdMYQDTzmSnaSzsbO6jkQkdaV0UsjIgClT4PgLD6X1mJMAXYEkIqktpZNCs2Ywfjx06gQHblgCwNpXl0UclYhIdFI6KRSbO5eDJgbzW3z227/B3LkRByQiEg0lBYDcXNru+JhZjOSkXS/oCiQRSVlKCgADB1KvvjGyzr9oU2cttGgRdUQiIpFQUoDgZrW//Y237Whe2nViMBmSupBEJAUpKRTZuJE/7fof/sdv0KM5RSRlKSkUGTiQrLS1FJClR3OKSMpSUijSvz9ZFwxmA5lsP3d81NGIiERCSSFGVsvvAfjswRfgxBM1riAiKUdJIUabz+YDUFDYWuMKIpKSlBRi9DnrUF6rN4TmdTbRqfB9+j06gSVLoo5KRKTmKCnEaDa4LwNzJ3PN4U+wpl4HFnyYwWOPRR2ViEjNSemH7JRkZ5/+eGe4+jyYNQvefDPqiEREak7ckoKZPQgMB9a5e7cSygcCzwKfhIuecffr4hVPedWtC3feCQcdFEyUt2tX1BGJiNSceLYUpgJ3AtP2UecNdx8exxgqpU2b4P2nP402DhGRmha3MQV3fx34Ml7brwnusGABvP9+1JGIiNSMqAea+5vZQjP7t5kdUVolM7vYzPLMLG/9+vU1FpwZDB4Mt9xSY7sUEYlUlElhAXCwu/cE7gBmlVbR3e9z9xx3z8nMzKyxAAG6dIHly2t0lyIikYksKbj7ZnffGn5+Hkg3swOiiqc0SgoikkoiSwpmdqCZWfi5bxjLxqjiKU2XLrBxI9Rgr5WISGTKlRTM7Fdm1sQCD5jZAjMbXMY6M4C5wGFmVmBm483s52b287DKT4ElZrYQuB04y929KgcTD126BO9qLYhIKijvJakXuPttZjYE2B8YDTwCvFTaCu5+9r426O53ElyymtD69oWnn4YjSh0GFxGpPcqbFCx8HwY84u5Li7p+arvmzeEnP4k6ChGRmlHeMYX3zOwlgqTwopllAIXxCyuxLF8ODz0UdRQiIvFX3qQwHpgE9HH3bUA6cH7cokowzzwDF1wAX30VdSQiIvFV3qTQH/jA3b82s/OAPwCb4hdWYjnqqOB93rxo4xARibfyJoW7gW1m1hO4AviIfc9pVKv07QsNG8LUqVFHIiISX+VNCjvDy0VHAne6+11ARvzCSiwZGfDrX8PMmfDcc1FHIyISP+VNClvM7HcEl6I+Z2Z1CMYVUsZvfxtMpf3ZZ1FHIiISP+W9JPVM4ByC+xU+N7N2wE3xCyvxNGkCCxdCvXpRRyIiEj/laim4++fAdKCpmQ0Htrt7yowpFGnYENLSYPJkPWtBRGqn8k5zcQYwDzgdOAN418xS9tfid9/Bs8/C5s1RRyIiUr3KO6ZwFcE9CmPdfQzQF7g6fmEltsGDYedOyM2NOhIRkepV3qRQx93XxXzfWIF1a50f/QgaNYKXSp35SUQkOZV3oPkFM3sRmBF+PxN4Pj4hJb769eH445UURKT2KVdScPffmNko4Ohw0X3u/o/4hZX4zjgDXnstGF+oXz/qaEREqocl4CMM9iknJ8fz8vKiDkNEJKmY2XvunlNWvX22FMxsC1BS1jDA3b1JJeOrFdyDm9natIk6EhGR6rHPwWJ3z3D3JiW8MlI9IQBccQV06xZciSQiUhuk7BVE1eGoo+Drr0G9WSJSWygpVMGJJ4IZ/M//wEcfRR2NiEjVKSlUQYsWcOedwZxIRx8NH3wQdUQiIlWjpFBFv/gFzJ0L550XtBpERJJZeW9ek33o0gX++teooxARqTq1FKqJO7z6KsyZE3UkIiKVp5ZCNbrsMsjMhBNOiDoSEZHKUUuhmpjBqFHwxhuwbl3Z9UVEEpGSQjUaNQoKC4NnLYiIJCMlhWrUowd07gxTpgRjDCIiySZuScHMHjSzdWa2pJRyM7PbzWylmS0ys97xiqWmmMHll8OKFfDpp1FHIyJScfFsKUwFhu6j/GSgU/i6GLg7jrHUmPPPh//+F9q1izoSEZGKi1tScPfXgS/3UWUkMM0D7wDNzKx1vOKpKQ0aQOPGwXMWZs2KOhoRkYqJckyhDRDbyVIQLvsBM7vYzPLMLG/9+vU1ElxV3X8//PjHwdVIIiLJIikGmt39PnfPcfeczMzMqMMplwsugNat4fe/16CziCSPKJPCGqBtzPescFmt0KgRXH01vPkmvPBC1NGIiJRPlElhNjAmvArpKGCTu6+NMJ5qN348dOgAV10V3L8gIpLo4nlJ6gxgLnCYmRWY2Xgz+7mZ/Tys8jzwMbASuB/4RbxiiUq9enDttbBtG6ytVelORGor8yTr8M7JyfG8JHrU2a5dwZhCXc0yJSIRMrP33D2nrHpJMdCczNLSgoTw5ZfBA3mSLAeLSIpRUqghTz8Nl14Kzz8fdSQiIqVTUqgh48bBIYfAH/8YdSQiIqVTUqgh6enwy18Gj+5cujTqaERESqakUINGjw6Sw5QpUUciIlIyJYUalJkJP/lJMGGeiEgi0oWSNezhh6F+/aijEBEpmVoKNawoIXzyCSTJ3H4ikkKUFCLw9dfBU9quuirqSERE9qSkEIFmzeCii4IB5/z8qKMREdlNSSEi11wDLVrAlVdGHYmIyG5KChFp1gx++1t49VW1FkQkcSgpROiiiyAjA3Jzo45ERCSgS1Ij1KwZrF4N++8fdSQiIgG1FCJWlBDmzQueuyAiEiUlhQTw8cfwox8Fg88iIlFSUkgAhxwCY8fCHXfA559HHY2IpDIlhQQxaRJ8/z3cc0/UkYhIKlNSSBCdOsHw4cHT2TZtijoaEUlVSgoJ5Npr4Ztv4K23oo5ERFKVLklNIL17Q0FBcKeziEgU1FJIMEUJ4V//gq1bo41FRFKPkkICWr4cTj0Vrr466khEJNUoKSSgLl3gkkvg9tth/vyooxGRVKKkkKBuuAEOPBAuvBB27Ig6GhFJFUoKCappU7jrLli0CG6+OepoRCRVKCkksNNOg9GjITMz6khEJFXoktQEN21a1BGISCqJa0vBzIaa2QdmttLMJpVQPs7M1ptZfvi6MJ7xJLNp0+C666KOQkRqu7i1FMwsDbgLOAkoAOab2Wx3X7ZX1cfdfUK84qgt3n4b7rsP+vWDIUOijkZEaqt4thT6Aivd/WN3/x6YCYyM4/5qtVtugSOOgPPOg48+ijoaEamt4pkU2gCfxnwvCJftbZSZLTKzp8ysbUkbMrOLzSzPzPLWr18fj1gTXqNG8Mwz4A4nnwwbNkQdkYjURlFfffRPoL279wBeBh4uqZK73+fuOe6ek5nCl+J06gSzZ8Onn8Ijj0QdjYjURvG8+mgNEPuXf1a4rJi7b4z5OgX4SxzjqRV+9CNYuDBIECIi1S2eLYX5QCcz62Bm9YCzgNmxFcysdczXEcDyOMZTa3TuDGawZAn87/8GXUoiItUhbi0Fd99pZhOAF4E04EF3X2pm1wF57j4buMzMRgA7gS+BcfGKpzaaPh1uvBG2b4frrw8ShYhIVZgn2Z+ZOTk5npeXF3UYCaGwEH72M5gyBSZOhL/+FepEPUokIgnJzN5z95yy6umO5iRWpw7ce29wZdKtt8L69fDQQ1BXZ1VEKkm/PpJcnTrwt79By5bwz3/Ct99CRkbUUYlIslJnQy1gBleDanqzAAAM9klEQVRdBa+/HiSEr74KLlsVEakoJYVapF694P2SS+DII2HOnGjjEZHko6RQC117LRxwAJx0EvzhD/D991FHJCLJQkmhFjrsMHj33eBZDH/8YzCJ3gcfRB2ViCQDJYVaKiMDpk6FWbNg2zbYb7+oIxKRZKCkUMuNHAnLlkFWVnDn87hx8NRTugtaREqmpJAC0tKC9y++gPnz4fTToW9feOWVaOMSkcSjpJBCDjwQFi0KupXWrQsGok88EVavjjoyEUkUSgopJi0Nxo6FDz+E226DNWugefOg7LPPgqkzRCR1KSmkqPr14bLLYPnyYFC6sBAGDYLDD4ebb4aNG8vehojUPkoKKa5oZlV3uPpqaNUKrrwS2rSBMWNgwYJo4xORmqWkIEDQrXT22fDGG8G4w/jxweWs8+cH5Zs3w6pVkYYoIjVASUF+oHt3uOsuWLs2uAEO4NFHoUMHOP74YKB669ZIQxSROFFSkFLtt18wLTfAqacGD/IpKIDzzw+uZBo7NpiVVURqDyUFKZe2bYN5lD78EN58M+hq+vhjaNAgKH/iCVi8ONoYRaTq9DwFqRAzOPro4OUefN+xI3gC3NdfB11P554L55wTJBIRSS5qKUilFV25lJ4eTLh3xx1Bl9OkSdCuHfzlL9HGJyIVp6Qg1aJlS5gwAebOhZUr4brrYODAoOzdd+HYY4MnxOnuaZHEpqQg1e7QQ4N7Hvr2Db5v3gybNsHEidC+PeTkBFN6f/11pGGKSAmUFCTuTjoJFi6EFSvgz38O7om4/vrdE/W99BK88AJ89120cYoImCfZHMo5OTmel5cXdRhSRV99BfvvH3w+/njIzQ3GIwYPDi5/HTYsuLtaRKqHmb3n7jll1VNLQSJRlBAAnn8ennsuuFFu/ny44AI47bTd5Z98ouc/iNQUtRQkobgHXU1bt8KAAbBlS/C86QMPhBEjgvmYcnJ2X/kkIuWjloIkJTPIzg4SAkCdOvD3v0OvXjBlSjB43bMnzJkTbZwitZWSgiS0/fbbPTnf55/DPfdAw4bQpElQvnQp/PvfsGtXtHGK1BZxTQpmNtTMPjCzlWY2qYTy+mb2eFj+rpm1j2c8ktyaNg3unH733aALCeDuu4NB6XbtguTx6KPBLK9J1isqkjDiNs2FmaUBdwEnAQXAfDOb7e7LYqqNB75y945mdhbwZ+DMeMUktc8tt8AJJ8D06fCPf8CDD0KLFrBhQ1B+1VXBg4RatoTMzCCxtGq1e/bXRYuCcYv0dKhXL3hv1CiYERaCeyncg+VpaUH3Vp06QV0IHk5kpjEOqT3iOfdRX2Clu38MYGYzgZFAbFIYCUwOPz8F3Glm5sk2+i2RqVcPfvKT4LVrFyxbFnQzFdm6Nbg/4q23gkRRWAgdO+5OCr/6VXA5bKxDDw3uyoZgu6+9tmd5x47BNiF4xnXs+mbQqVMw7QfAkCHw+uu7E4dZsH5+flA+cmTwDItYhxwCRddSnHZaMAHh3uXz5u2Ob+/yDh2C1hTAqFHBse9dPndu8Pn000suL1p2xhl7lpsFNyAW7fPMM+Htt39Y/vrrwfezzy65vOhnds45u2Mp0r797p/5uefCO+/sWX7wwbvHlEaP/mF5+/bw8svB5zFjSl4/trzoZxVb/tJLweexY0suf/HF8pWPG1dy+QsvBJ/PP/+H5e3alVzesyfMmEHcxTMptAE+jfleAPQrrY677zSzTUALYENsJTO7GLgYoF27dvGKV5JcWlowIV/37ruX3Xbb7s+FhbBtG2zfvnvZzTcHyWLHjuD1/ffBmEWRSy8NfnF//32QdNyhWbPd5ePGBdN5FBYGZe67n3kNwS/l7Ow9yw84YHf5oEHBL4lYseUnnABZWaWXH3tscGVWrMzM3Z8HDNjz+97lRx215+XBe5f37Ru0rmB3l1zLlrvLc3KgcePSy7Ozd8+kW1J5jx5BKyxWbHm3bkHLLFbs/SuHH77nc8Xd9yzv3Bl27ix9/c6dg/MeK/bn2bHjD2+qLKs8dvuHHPLD6eVj12/fHr75pnzlRa3XeIvbJalm9lNgqLtfGH4fDfRz9wkxdZaEdQrC7x+FdTaUtE3QJakiIpWRCJekrgFiJ0/OCpeVWMfM6gJNAT0yXkQkIvFMCvOBTmbWwczqAWcBs/eqMxsYG37+KTBH4wkiItGJ25hCOEYwAXgRSAMedPelZnYdkOfus4EHgEfMbCXwJUHiEBGRiMT1yWvu/jzw/F7Lron5vB04PZ4xiIhI+emOZhERKaakICIixZQURESkmJKCiIgUS7rnKZjZeqCyj38/gL3ulk5iOpbEpGNJTDoWONjdM8uqlHRJoSrMLK88d/QlAx1LYtKxJCYdS/mp+0hERIopKYiISLFUSwr3RR1ANdKxJCYdS2LSsZRTSo0piIjIvqVaS0FERPZBSUFERIqlTFIws6Fm9oGZrTSzSVHHU1FmtsrMFptZvpnlhcuam9nLZrYifN+/rO1EwcweNLN14UOVipaVGLsFbg/P0yIz6x1d5D9UyrFMNrM14bnJN7NhMWW/C4/lAzMbEk3UP2Rmbc3sNTNbZmZLzexX4fKkOy/7OJZkPC8NzGyemS0Mj+XacHkHM3s3jPnx8HEEmFn98PvKsLx9lYNw91r/Ipi6+yPgEKAesBDoGnVcFTyGVcABey37CzAp/DwJ+HPUcZYS+7FAb2BJWbEDw4B/AwYcBbwbdfzlOJbJwJUl1O0a/lurD3QI/w2mRX0MYWytgd7h5wzgwzDepDsv+ziWZDwvBjQOP6cD74Y/7yeAs8Ll9wCXhJ9/AdwTfj4LeLyqMaRKS6EvsNLdP3b374GZwMiIY6oOI4GHw88PA6dFGEup3P11gudlxCot9pHANA+8AzQzs9Y1E2nZSjmW0owEZrr7d+7+CbCS4N9i5Nx9rbsvCD9vAZYTPDM96c7LPo6lNIl8Xtzdt4Zf08OXAycAT4XL9z4vRefrKeBEM7OqxJAqSaEN8GnM9wL2/Y8mETnwkpm9Z2YXh8taufva8PPnQKuSV01IpcWerOdqQtit8mBMN15SHEvY5dCL4K/SpD4vex0LJOF5MbM0M8sH1gEvE7Rkvnb3nWGV2HiLjyUs3wS0qMr+UyUp1AYD3L03cDLwSzM7NrbQg/ZjUl5fnMyxh+4GDgWygbXAzdGGU35m1hh4Grjc3TfHliXbeSnhWJLyvLj7LnfPJniufV/g8Jrcf6okhTVA25jvWeGypOHua8L3dcA/CP6xfFHUhA/f10UXYYWVFnvSnSt3/yL8j1wI3M/uroiEPhYzSyf4JTrd3Z8JFyfleSnpWJL1vBRx96+B14D+BN11RU/KjI23+FjC8qbAxqrsN1WSwnygUziCX49gQGZ2xDGVm5ntZ2YZRZ+BwcASgmMYG1YbCzwbTYSVUlrss4Ex4dUuRwGbYrozEtJefes/Jjg3EBzLWeEVIh2ATsC8mo6vJGG/8wPAcne/JaYo6c5LaceSpOcl08yahZ8bAicRjJG8Bvw0rLb3eSk6Xz8F5oQtvMqLerS9pl4EV098SNA/d1XU8VQw9kMIrpZYCCwtip+g7/BVYAXwCtA86lhLiX8GQfN9B0F/6PjSYie4+uKu8DwtBnKijr8cx/JIGOui8D9p65j6V4XH8gFwctTxx8Q1gKBraBGQH76GJeN52cexJON56QH8J4x5CXBNuPwQgsS1EngSqB8ubxB+XxmWH1LVGDTNhYiIFEuV7iMRESkHJQURESmmpCAiIsWUFEREpJiSgoiIFFNSkJRlZm+H7+3N7Jxq3vbvS9qXSKLTJamS8sxsIMFsmsMrsE5d3z0XTUnlW929cXXEJ1KT1FKQlGVmRbNR3ggcE865PzGckOwmM5sfTqb2s7D+QDN7w8xmA8vCZbPCSQqXFk1UaGY3Ag3D7U2P3Vd4R/BNZrbEgudjnBmz7Vwze8rM3jez6VWd7VKkMuqWXUWk1ptETEsh/OW+yd37mFl94C0zeyms2xvo5sGUywAXuPuX4ZQE883saXefZGYTPJjUbG8/IZigrSdwQLjO62FZL+AI4DPgLeBo4M3qP1yR0qmlIPJDgwnm+cknmIK5BcH8OADzYhICwGVmthB4h2Bisk7s2wBghgcTtX0B/B/QJ2bbBR5M4JYPtK+WoxGpALUURH7IgEvd/cU9FgZjD9/s9X0Q0N/dt5lZLsFcNJX1XcznXej/p0RALQUR2ELwGMciLwKXhNMxY2adw9lp99YU+CpMCIcTPDaxyI6i9ffyBnBmOG6RSfB4z4SYoVME9JeICAQzUu4Ku4GmArcRdN0sCAd711Pyo05fAH5uZssJZtt8J6bsPmCRmS1w93Njlv+DYH78hQQze/7W3T8Pk4pI5HRJqoiIFFP3kYiIFFNSEBGRYkoKIiJSTElBRESKKSmIiEgxJQURESmmpCAiIsX+P9AoiHcTXd+RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa464b432d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(plot_loss,'r.')\n",
    "plt.plot(plot_loss2,'b--')\n",
    "plt.legend([\"1-Layer LSTM\",\"Multi-Layer LSTM\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.title(\"Loss During Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWE-14Lq44iS"
   },
   "source": [
    "여러분의 모델은 이 두 문장은 잘 완성할 수 있지만, 언어에 대한 나머지 부분에 대해서는 아무것도 모릅니다. (마치 노래 한 곡의 단 두 단락을 배운 것과 같습니다.) 일반적으로, 우리가 언어를 이해하기 위해 노력할 때, 모델의 복잡성(깊이)을 높여 더 복잡한 [말뭉치(corpus)](#corpora \"actually corpora\")들에 대해 배울 수 있겠지만, 이로 인해 오히려 **overfitting** 문제를 발생시킬 수도 있습니다. 여기서 드롭아웃은 오버피팅을 줄이는 한 방법입니다. 우리가 특정 유형의 언어나 캡션에 대해 배울 때 이러한 전략을 잘 기억하고 있어야 할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZXPjzuW44iS"
   },
   "source": [
    "### MSCOCO 캡션 데이터셋을 사용하여 RNN  모델 학습시키기\n",
    "이제 MSCOCO [Microsoft Common Objects in Context](http://mscoco.org/)의 이미지 캡션 데이터셋을 사용하여 RNN 모델이 캡션을 이해하도록 학습시키겠습니다. 아래는 데이터를 읽고, 포맷하고, TensorFlow에 공급하는 한 방법을 보여줍니다. 먼저 캡션 파일을 읽은 다음, 구두점을 제거 후 학습시킵니다. 시간 제약 상, 이번 실습에서는 전체 데이터셋을 사용하지 않습니다. 하지만, 이 부분은 더 많은 데이터셋 또는 전체 데이터셋으로 바꾸어 학습하기 쉽습니다. 이를 쉽게 하는 방법을 여러분은 알고 계십니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3hz0lbB44iU"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "#import reader\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "num_steps=20\n",
    "## Read Training files\n",
    "with open(\"/dli/data/mdt/mscoco/captions_train2014.json\") as data_file:\n",
    "         data=json.load(data_file)\n",
    "\n",
    "TotalNumberofCaptions=len(data['annotations'])\n",
    "\n",
    "sentences=[]\n",
    "\n",
    "##Create a list of all of the sentences.\n",
    "for i in range(TotalNumberofCaptions):\n",
    "        sentences+=[re.sub('[^A-Za-z0-9]+',' ',data['annotations'][i]['caption']).lower()]\n",
    "\n",
    "TotalWordList=[]\n",
    "for i in range(TotalNumberofCaptions):\n",
    "        TotalWordList+=re.sub('[^A-Za-z0-9]+',' ',data['annotations'][i]['caption']).lower().split()\n",
    "\n",
    "#Determine number of distinct words \n",
    "distinctwords=collections.Counter(TotalWordList)\n",
    "#Order words \n",
    "count_pairs = sorted(distinctwords.items(), key=lambda x: (-x[1], x[0])) #ascending order\n",
    "words, occurence = list(zip(*count_pairs))\n",
    "DictionaryLength=occurence.index(4) #index for words that occur 4 times or less\n",
    "words=['PAD','UNK','EOS']+list(words[:DictionaryLength])\n",
    "word_to_id=dict(zip(words, range(len(words))))\n",
    "#Tokenize Sentence\n",
    "Tokenized=[]\n",
    "for full_words in sentences:\n",
    "        EmbeddedSentence=[word_to_id[word] for word in full_words.split() if word in word_to_id]+[word_to_id['EOS']]\n",
    "        #Pad sentences that are shorter than the number of steps \n",
    "        if len(EmbeddedSentence)<num_steps:\n",
    "            b=[word_to_id['PAD']]*num_steps\n",
    "            b[:len(EmbeddedSentence)]=EmbeddedSentence\n",
    "        if len(EmbeddedSentence)>num_steps:\n",
    "            b=EmbeddedSentence[:num_steps]\n",
    "        if len(b)==EmbeddedSentence:\n",
    "            b=EmeddedSentence\n",
    "        b=[word_to_id['UNK'] if x>=DictionaryLength else x for x in b] #turn all words used 4 times or less to 'UNK'\n",
    "        #print(b)\n",
    "        Tokenized+=[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpyAMiIM44iY"
   },
   "source": [
    "우리는 이러한 캡션을 \"토큰화(tokenize)\"하거나 각 단어를 숫자(인기 기준 내림차순)로 변환할 수 있습니다. 또한 문장의 길이는 다양하기 때문에 표준 입력과 출력 tensor를 만들기 위해 짧은 문장에는 0을 채워 넣고, 긴 문장은 잘라냈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzE_2Yls44ia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 142, 508, 9, 619, 415, 276, 57, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[142, 508, 9, 619, 415, 276, 57, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Number of words in this dictionary 8768\n"
     ]
    }
   ],
   "source": [
    "############################################# Parameters #####################################################\n",
    "\n",
    "num_hidden=256\n",
    "num_steps=20\n",
    "dict_length=len(words)\n",
    "batch_size=4\n",
    "\n",
    "\n",
    "## Create labels\n",
    "Label=[]\n",
    "for caption in Tokenized:\n",
    "    Label+=[caption[1:]+[word_to_id['PAD']]]\n",
    "\n",
    "NumberofCasestoEvaluate=20\n",
    "TrainingInputs=Tokenized[:NumberofCasestoEvaluate]\n",
    "LabelInputs=Label[:NumberofCasestoEvaluate]\n",
    "\n",
    "#Print out some variables \n",
    "print(TrainingInputs[0])\n",
    "#첫단어부터 끝단어까지\n",
    "\n",
    "print(LabelInputs[0])\n",
    "# 정답을 표시하는거, 첫단어 빼고 나머지 단어 label\n",
    "\n",
    "print(\"Number of words in this dictionary\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O34L8H5T44ie"
   },
   "source": [
    "여러분은 다음 두 가지를 알 수 있습니다.\n",
    "1. 우리의 [라벨](#labels \"labels are the outputs that we want our network to generate\")은 training 세트에서 다음으로 나오는 *토큰(token)*입니다. \n",
    "2. 이 사전(dictionary)은 사실 훨씬 더 큽니다.\n",
    "\n",
    "우리는 학습 시간에 더 큰 혜택을 얻기 위해 병렬 프로세싱과 추가 GPU를 사용하여 4개의 배치(`batch_size`)로 데이터를 네트워크에 제공하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JlafJxT44ig"
   },
   "outputs": [],
   "source": [
    "#Create our input queue\n",
    "def data_input_queue(TrainingInputs, LabelInputs, num_steps):\n",
    "    train_input_queue = tf.train.slice_input_producer(\n",
    "                                    [TrainingInputs, LabelInputs],\n",
    "                                    shuffle=True)\n",
    "\n",
    "    ##Set our train data and label input shape for the queue\n",
    "    TrainingInput=train_input_queue[0]\n",
    "    LabelInput=train_input_queue[1]\n",
    "    TrainingInput.set_shape([num_steps])\n",
    "    LabelInput.set_shape([num_steps])\n",
    "    min_after_dequeue=100000\n",
    "    capacity = min_after_dequeue + 3 * batch_size \n",
    "    #input_x, target_y\n",
    "    train_x, train_y = tf.train.batch([TrainingInput, LabelInput],\n",
    "                                                 batch_size=batch_size ,\n",
    "                                                 capacity=capacity,\n",
    "                                                 num_threads=4)\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOjcauMF44im"
   },
   "source": [
    "이제 MSCOCO 캡션으로 RNN을 학습시킬 준비가 되었습니다. 자유롭게 레이어 수를 변경하여 실습하고, 다시 드롭아웃을 수행해 보십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe0c8V5244in"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 loss:  8.822754\n",
      "iteration:  100 loss:  0.121202126\n",
      "iteration:  200 loss:  0.09813916\n",
      "iteration:  300 loss:  0.12715036\n",
      "iteration:  400 loss:  0.095678665\n",
      "iteration:  500 loss:  0.11264532\n",
      "iteration:  600 loss:  0.12753458\n",
      "iteration:  700 loss:  0.07022795\n",
      "iteration:  800 loss:  0.13134536\n",
      "iteration:  900 loss:  0.11306753\n",
      "iteration:  1000 loss:  0.10637943\n",
      "iteration:  1100 loss:  0.12407749\n",
      "iteration:  1200 loss:  0.087161444\n",
      "iteration:  1300 loss:  0.115499035\n",
      "iteration:  1400 loss:  0.1108933\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "num_layers=1\n",
    "dropout = 1.0\n",
    "\n",
    "loss_mscoco=[]\n",
    "#######################################################################################################\n",
    "TrainingInputs=Tokenized[:NumberofCasestoEvaluate]\n",
    "LabelInputs=Label[:NumberofCasestoEvaluate]\n",
    "\n",
    "\n",
    "variables_dict = {\n",
    "    \"weights_mscoco\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],\n",
    "                                                     stddev=1.0,dtype=tf.float32),name=\"weights_mscoco\"),\n",
    "    \"biases_mscoco\": tf.Variable(tf.truncated_normal([dict_length],\n",
    "                                                     stddev=1.0,dtype=tf.float32), name=\"biases_mscoco\")}\n",
    "\n",
    "\n",
    "# Create input data\n",
    "train_x, train_y =data_input_queue(TrainingInputs, LabelInputs, num_steps)\n",
    "mscoco_dict=words\n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), train_x) #[batch,num_steps,dictionary_length]\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), train_y),num_steps,1)#[batch,num_steps,dictionary_length]\n",
    "#임베딩 룩업테이블\n",
    "\n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "\n",
    "input_keep_prob=dropout\n",
    "output_keep_prob=dropout\n",
    "\n",
    "#Create a multilayer RNN\n",
    "\n",
    "layer_cell=[]\n",
    "for _ in range(num_layers):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "    ############# add dropout #########################\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,\n",
    "                                          input_keep_prob=dropout,\n",
    "                                          output_keep_prob=dropout)\n",
    "    layer_cell.append(lstm_cell)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell(layer_cell, state_is_tuple=True)\n",
    "# RNN 쌓는거\n",
    "\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=lstm_cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden])\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights_mscoco\"]) +variables_dict[\"biases_mscoco\"]\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost,aggregation_method = tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
    "\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        for i in range(1500):\n",
    "            x_input,y_input=sess.run([train_x, train_y])\n",
    "            loss,_,y_target,x_input,y_input,y_pred=sess.run([cost,optimizer,y_target_reshape,train_x, train_y,pred])\n",
    "            loss_mscoco.append([loss])\n",
    "            if i% 100==0:\n",
    "                print(\"iteration: \",i, \"loss: \",loss)  \n",
    "        print(\"Done Training\")\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeQ2RTx244ir"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence\n",
      "[u'a', u'panoramic', u'photo', u'of', u'a', u'kitchen', u'and', u'dining', u'room', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Target\n",
      "[u'panoramic', u'photo', u'of', u'a', u'kitchen', u'and', u'dining', u'room', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Predicted words\n",
      "[u'panoramic', u'view', u'of', u'a', u'kitchen', u'and', u'dining', u'room', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
     ]
    }
   ],
   "source": [
    "#Lets look at one input data point and its prediction\n",
    "print(\"Input Sentence\")\n",
    "batch_element=2\n",
    "print([words[ind] for ind in x_input[batch_element,:]])\n",
    "print(\"Target\")\n",
    "print([words[ind] for ind in y_input[batch_element,:]])\n",
    "print(\"Predicted words\")\n",
    "print([words[ind] for ind in np.argmax(y_pred[batch_element::batch_size],1)])\n",
    "\n",
    "#predict가 target하고 똑같으면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M43tdffK44iv"
   },
   "source": [
    "여러분은 지금까지 이전 단어에서 다음 단어를 예측하기 위해 RNN을 사용하는 법과 RNN의 언어에 대한 이해를 공부했습니다.\n",
    "\n",
    "이 모델을 구현하여 어떤 문제를 해결할 수 있을까요?\n",
    "\n",
    "만약 여러분이 이것을 정말 잘 활용할 수 있는 실력을 키운다면, 우리는 다른 사람의 작문 스타일을 흉내내거나, 과거의 실적을 바탕으로 주식시장을 예측한다거나, 문자 메시지에서 다음 단어를 제안하기 시작할 수 있습니다. \n",
    "\n",
    "하지만 지금까지 실습한 수준의 네트워크에서 한 단어(word) 이상을 출력하도록 시도했다면, 그 성과는 매우 실망스러웠을 것입니다. \n",
    "\n",
    "여러분의 네트워크가 전체 문장(sentence)을 생성하도록 하기 위한 한가지 방법은 어떤 맥락을 제공하는 것입니다. 다음 장에서는 네트워크가 이미지를 이해하도록 하는 법을 배우도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "UrIWSV7644ix"
   },
   "source": [
    "## References \n",
    "[1] Imanol Schlab. TensorFlow Input Pipeline Example. http://ischlag.github.io/\n",
    "\n",
    "[2] Denny Britz. Practical Examples for RNNs in TensorFlow https://github.com/dennybritz/tf-rnn\n",
    "\n",
    "[3]Lin, Tsung-Yi, et al. \"Microsoft coco: Common objects in context.\" European Conference on Computer Vision. Springer International Publishing, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uVm9Ths44ix"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Word Generation with TensorFlow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
